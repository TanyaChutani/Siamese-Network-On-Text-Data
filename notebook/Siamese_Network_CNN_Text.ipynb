{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Siamese_Network_CNN_Text.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_KV341tqW7P",
        "colab_type": "code",
        "outputId": "804dbf6b-411c-417f-8654-28ba25098684",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JogWW6mLqRyl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp '/content/drive/My Drive/train.csv.zip' '/content/train.csv.zip'\n",
        "!cp '/content/drive/My Drive/GoogleNews-vectors-negative300.bin' '/content/GoogleNews-vectors-negative300.bin'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFtZVStqMKL1",
        "colab_type": "code",
        "outputId": "405f6555-99d6-430d-f6ac-93a52b82c891",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!unzip '/content/train.csv.zip'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/train.csv.zip\n",
            "  inflating: train.csv               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKvCQNnWlkRg",
        "colab_type": "text"
      },
      "source": [
        "## Importing Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNGO5ZJk1f21",
        "colab_type": "code",
        "outputId": "e0cc2e9e-035b-4d19-8fe1-41c70c2b4216",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import nltk\n",
        "import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import re, nltk, gensim\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding,GRU,Dense,Input,\\\n",
        "BatchNormalization,Bidirectional,concatenate,Dropout,Conv1D,\\\n",
        "MaxPooling1D,Flatten,add,Lambda\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ma8V0_0glq1I",
        "colab_type": "text"
      },
      "source": [
        "## Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMAGuQr9B54c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(dataset):\n",
        "  train=pd.read_csv(dataset)\n",
        "  train.dropna(axis=0, inplace=True)\n",
        "  return train\n",
        "\n",
        "data=load_data('train.csv')\n",
        "data=data[:100000]\n",
        "#Creating two list one for left and another for the right question\n",
        "def list_data(train):\n",
        "  q1 = pd.Series(train.question1.tolist()).astype(str)\n",
        "  q2 = pd.Series(train.question2.tolist()).astype(str)\n",
        "  return q1,q2\n",
        "\n",
        "q1,q2=list_data(data)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0rvDcCLXZ7D",
        "colab_type": "code",
        "outputId": "78a2c05b-bfe5-49d5-feb2-74687e95e9b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#Checking for the output counts (Check for data imbalance)\n",
        "data['is_duplicate'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    62746\n",
              "1    37254\n",
              "Name: is_duplicate, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F26PW3G3mGGx",
        "colab_type": "text"
      },
      "source": [
        "## Preparing the text data\n",
        "\n",
        "### Data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5Mjs029358_",
        "colab_type": "code",
        "outputId": "a8fa8fe3-6be4-4c91-e186-6d671fc7f3f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "def text_clean(corpus):\n",
        "    cleaned_corpus = pd.Series()\n",
        "    for row in corpus:\n",
        "        qs_list = []\n",
        "        for word in row.split():\n",
        "            word = word.lower()\n",
        "            word = re.sub(r\"[^a-zA-Z0-9^.']\",\" \",word)\n",
        "            p1 = re.sub(pattern='[^a-zA-Z0-9]',repl=' ',string=word)\n",
        "            qs_list.append(p1)\n",
        "        cleaned_corpus = cleaned_corpus.append(pd.Series(' '.join(qs_list)))\n",
        "    return cleaned_corpus\n",
        "\n",
        "all_corpus = q1.append(q2)\n",
        "all_corpus = text_clean(all_corpus)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fW0pNaR5UhB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The data is in format like all q1 are the in the starting \n",
        "#rows of all_corpus\n",
        "#then once q1 gets finished, q2 starts. So again \n",
        "#separating q1 and q2 and merging them into a data frame.\n",
        "def clean_data(all_corpus,q1,q2,train):\n",
        "  q1 = all_corpus[0:q1.shape[0]]\n",
        "  q2 = all_corpus[q2.shape[0]::]\n",
        "  data_out = pd.DataFrame({'q1': q1, 'q2': q2})\n",
        "  data_out.index=list(range(0,len(data_out)))\n",
        "  data_out['output']=train['is_duplicate']\n",
        "  return data_out\n",
        "data_new=clean_data(all_corpus,q1,q2,data)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkcGCEBTmynw",
        "colab_type": "text"
      },
      "source": [
        "### Creating word to index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zP20saPEaKqA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creating word to index using keras tokenizer\n",
        "def word_to_index(all_corpus):\n",
        "  lines = []\n",
        "  for key in all_corpus:\n",
        "    lines.append(key)\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(lines)\n",
        "  return(tokenizer.word_index)\n",
        "word2index=word_to_index(all_corpus)\n",
        "index2word = dict((v,k) for k,v in word2index.items())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CT6dn69Lm23C",
        "colab_type": "text"
      },
      "source": [
        "### Implementing word2vec embedding on text data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L05AHdP7rJUJ",
        "colab_type": "code",
        "outputId": "b6db48f6-6947-479e-8242-d7b139d82280",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# Loading pre-trained word vectors\n",
        "def load_embedding(EMBEDDING_FILE,embedding_dim):\n",
        "  word2vec_model = gensim.models.KeyedVectors.\\\n",
        "  load_word2vec_format(EMBEDDING_FILE, binary = True)\n",
        "  w2v = dict(zip(word2vec_model.wv.index2word,\\\n",
        "                 word2vec_model.wv.syn0))\n",
        "  \n",
        "# This will be the embedding matrix\n",
        "  embeddings = 1 * np.random.randn(len(word2index) \\\n",
        "                                   + 1, embedding_dim)  \n",
        "  embeddings[0] = 0  # So that the padding will be ignored\n",
        "\n",
        "\n",
        "  # Build the embedding matrix\n",
        "  for word, index in word2index.items():\n",
        "      if word in word2vec_model.vocab:\n",
        "          embeddings[index] = word2vec_model.word_vec(word)\n",
        "  return embeddings\n",
        "embedding_dim=300\n",
        "EMBEDDING_FILE = '/content/GoogleNews-vectors-negative300.bin'\n",
        "embeddings=load_embedding(EMBEDDING_FILE,embedding_dim)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRpbeZ1bm_qg",
        "colab_type": "text"
      },
      "source": [
        "### Max length \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ih2JQn9OcfYy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_length(all_corpus):\n",
        "  lines=[]\n",
        "  max_len=-1\n",
        "  for key in all_corpus:\n",
        "    for d in key:\n",
        "      if len(d.split())>max_len:\n",
        "        max_len=len(d.split())\n",
        "  return max_len\n",
        "\n",
        "max_len=max_length(all_corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOIHKX-enFyT",
        "colab_type": "text"
      },
      "source": [
        "## Creating training data \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGnLw9OjwBs3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#If len is not equal to max_len then doing post padding\n",
        "max_len=50\n",
        "def create_train_data(dataset,max_length,column):\n",
        "  X1=list()\n",
        "  for idx in range(len(dataset)):\n",
        "    for words in (data_new.iloc[idx][[column]].values):\n",
        "      numeric_seq = [word2index[word] for word \\\n",
        "                     in words.split() if word in word2index]\n",
        "      in_seq=numeric_seq\n",
        "      in_seq=pad_sequences([in_seq],maxlen=max_length,\\\n",
        "                           padding='post')[0]\n",
        "    X1.append(in_seq)\n",
        "  return X1\n",
        "\n",
        "\n",
        "q1=np.array(create_train_data(data_new,max_len,'q1'))\n",
        "q2=np.array(create_train_data(data_new,max_len,'q2'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaxJW46insqU",
        "colab_type": "text"
      },
      "source": [
        "## Train Test Split\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StilL-luN4t8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_train_test(q1,q2,data):\n",
        "  X = np.stack((q1, q2), axis=1)\n",
        "  X_train, X_test, y_train, y_test = X[:-10], \\\n",
        "  X[-10:],list(data['is_duplicate'])[:-10],list(data['is_duplicate'])[-10:]\n",
        "  train_q1 = X_train[:,0]\n",
        "  train_q2 = X_train[:,1]\n",
        "  test_q1 = X_test[:,0]\n",
        "  test_q2 = X_test[:,1]\n",
        "  return train_q1,train_q2,test_q1,test_q2,\\\n",
        "  y_train,y_test,X_train,X_test\n",
        "train_q1,train_q2,test_q1,test_q2,y_train,\\\n",
        "y_test,X_train,X_test=split_train_test(q1,q2,data)\n",
        "y_train=np.array(y_train)\n",
        "y_test=np.array(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ev5GCpGFny3B",
        "colab_type": "text"
      },
      "source": [
        "## Cosine distance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dl5sOVg_Z_cW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Cosine distance\n",
        "def cosine_distance(output):\n",
        "  x,y=output[0],output[1]\n",
        "  x = K.l2_normalize(x, axis=-1)\n",
        "  y = K.l2_normalize(y, axis=-1)\n",
        "  return -K.mean(x * y, axis=-1, keepdims=True)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktTtkm28n3HA",
        "colab_type": "text"
      },
      "source": [
        "## Contrastive Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8hbLMTTqe5x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Triplet loss\n",
        "def contrastive_loss(y_true, y_pred):\n",
        "    margin = 1\n",
        "    return K.mean(y_true * K.square(y_pred) + \\\n",
        "                  (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owXPgFP8oCko",
        "colab_type": "text"
      },
      "source": [
        "## First Model Stacked Birectional GRU with cosine distance\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFaJQdVcOd2T",
        "colab_type": "code",
        "outputId": "a2067bb9-e598-4f0d-e80c-b4117b751ceb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "input_q1 = Input(shape=(max_len,))\n",
        "input_q2 = Input(shape=(max_len,))\n",
        "\n",
        "embedding_layer = Embedding(len(embeddings), \n",
        "                 embedding_dim, \n",
        "                 weights=[embeddings], \n",
        "                 input_length=max_len, \n",
        "                 trainable=False)\n",
        "\n",
        "embedded_q1 = embedding_layer(input_q1)\n",
        "embedded_q2 = embedding_layer(input_q2)\n",
        "\n",
        "lstm_first = Bidirectional(GRU(64, return_sequences=True))\n",
        "\n",
        "lstm_q1_1 = lstm_first(embedded_q1)\n",
        "lstm_q2_1 = lstm_first(embedded_q2)\n",
        "\n",
        "dropout_layer = Dropout(0.2)\n",
        "\n",
        "lstm_q1_1 = dropout_layer(lstm_q1_1)\n",
        "lstm_q2_1 = dropout_layer(lstm_q2_1)\n",
        "\n",
        "lstm_second=Bidirectional(GRU(64,return_sequences=False))\n",
        "\n",
        "lstm_q1_2 = lstm_second(embedded_q1)\n",
        "lstm_q2_2 = lstm_second(embedded_q2)\n",
        "\n",
        "dropout_layer = Dropout(0.2)\n",
        "\n",
        "lstm_q1_2 = dropout_layer(lstm_q1_2)\n",
        "lstm_q2_2 = dropout_layer(lstm_q2_2)\n",
        "\n",
        "lstm_out_1=add([lstm_q1_1,lstm_q1_2])\n",
        "lstm_out_2=add([lstm_q2_1,lstm_q2_2])\n",
        "\n",
        "bn_one = BatchNormalization()\n",
        "\n",
        "bn_q1 = bn_one(lstm_out_1)\n",
        "bn_q2 = bn_one(lstm_out_2)\n",
        "\n",
        "output = Lambda(cosine_distance, name='cosine_distance')\\\n",
        "([bn_q1, bn_q2])\n",
        "\n",
        "model = Model(inputs=[input_q1,input_q2], outputs=output)\n",
        "model.summary()\n",
        "model.compile(loss=contrastive_loss, optimizer='adam',\\\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "callback = [ModelCheckpoint('question_pairs_weights_type1.h5',\\\n",
        "                            monitor='loss', save_best_only=True,mode='min')]\n",
        "\n",
        "history = model.fit([train_q1,train_q2],\n",
        "                    np.expand_dims(y_train,axis=-1),\n",
        "                    epochs=1,\n",
        "                    batch_size=10,\n",
        "                    callbacks=callback)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_17 (InputLayer)           [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_18 (InputLayer)           [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_8 (Embedding)         (None, 50, 300)      13730400    input_17[0][0]                   \n",
            "                                                                 input_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_10 (Bidirectional (None, 50, 128)      140544      embedding_8[0][0]                \n",
            "                                                                 embedding_8[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_11 (Bidirectional (None, 128)          140544      embedding_8[0][0]                \n",
            "                                                                 embedding_8[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 50, 128)      0           bidirectional_10[0][0]           \n",
            "                                                                 bidirectional_10[1][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 128)          0           bidirectional_11[0][0]           \n",
            "                                                                 bidirectional_11[1][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 50, 128)      0           dropout_16[0][0]                 \n",
            "                                                                 dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 50, 128)      0           dropout_16[1][0]                 \n",
            "                                                                 dropout_17[1][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 50, 128)      512         add_16[0][0]                     \n",
            "                                                                 add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "cosine_distance (Lambda)        (None, 50, 1)        0           batch_normalization_8[0][0]      \n",
            "                                                                 batch_normalization_8[1][0]      \n",
            "==================================================================================================\n",
            "Total params: 14,012,000\n",
            "Trainable params: 281,344\n",
            "Non-trainable params: 13,730,656\n",
            "__________________________________________________________________________________________________\n",
            "9999/9999 [==============================] - 1135s 114ms/step - loss: 0.6275 - accuracy: 0.6274\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G71orVS4ofP9",
        "colab_type": "text"
      },
      "source": [
        "## Result\n",
        "\n",
        "#### Model Prediction on positive example in Test Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fm5HnF0Wvww4",
        "colab_type": "code",
        "outputId": "87618b88-257c-4a03-f1eb-432509fa8f38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "data_new[-3:-2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>q1</th>\n",
              "      <th>q2</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>99997</th>\n",
              "      <td>who would win  black panther or batman</td>\n",
              "      <td>who would win in a fight between black panther...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            q1  ... output\n",
              "99997  who would win  black panther or batman   ...      1\n",
              "\n",
              "[1 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLiyrpcCdYCQ",
        "colab_type": "code",
        "outputId": "58b73a70-2c22-45fa-e84c-78a6e7c023b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_pred=model.predict([test_q1[-3:-2],test_q2[-3:-2]])\n",
        "pred_data=data_new[-3:-2]\n",
        "print(\"Model Prediction on positive example in Test Data\",\\\n",
        "      [np.argmax(i) for i in y_pred])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Prediction on positive example in Test Data [4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhexwhwVx4nk",
        "colab_type": "text"
      },
      "source": [
        "#### Model Prediction on negative example in Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URMiHr81w3pd",
        "colab_type": "code",
        "outputId": "9715ef7c-adf8-4248-e7c2-dee58ca54f9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "data_new[-10:-9]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>q1</th>\n",
              "      <th>q2</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>99990</th>\n",
              "      <td>when is a root canal treatment necessary</td>\n",
              "      <td>what is a root canal treatment</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              q1  ... output\n",
              "99990  when is a root canal treatment necessary   ...      0\n",
              "\n",
              "[1 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oF5JrBoqd0it",
        "colab_type": "code",
        "outputId": "c65b2d7a-6f8a-4d96-ac48-396f32f1e236",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_pred=model.predict([test_q1[-5:-4],test_q2[-5:-4]])\n",
        "pred_data=data_new[-5:-4]\n",
        "print(\"Model Prediction on negative example in Test Data\",\\\n",
        "      [np.argmax(i) for i in y_pred])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Prediction on negative example in Test Data [9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp_Rjdqsohxc",
        "colab_type": "text"
      },
      "source": [
        "## Second model CNN Siamese Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84JlKjA3fmuP",
        "colab_type": "code",
        "outputId": "522a66f1-8eec-4942-9f5e-e4b9311e7d7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "max_len=50\n",
        "embedding_dim=300\n",
        "\n",
        "input_q1 = Input(shape=(max_len,))\n",
        "input_q2 = Input(shape=(max_len,))\n",
        "\n",
        "embedding_layer = Embedding(len(embeddings), \n",
        "                 embedding_dim, \n",
        "                 weights=[embeddings], \n",
        "                 input_length=max_len, \n",
        "                 trainable=False)\n",
        "\n",
        "embedded_q1 = embedding_layer(input_q1)\n",
        "embedded_q2 = embedding_layer(input_q2)\n",
        "\n",
        "conv_first = Conv1D(filters=64,kernel_size=3,activation='relu')\n",
        "\n",
        "conv_q1_1 = conv_first(embedded_q1)\n",
        "conv_q2_1 = conv_first(embedded_q2)\n",
        "\n",
        "max_pool_first=MaxPooling1D(pool_size=2)\n",
        "\n",
        "max_q1_1=max_pool_first(conv_q1_1)\n",
        "max_q2_1=max_pool_first(conv_q2_1)\n",
        "\n",
        "dropout_layer = Dropout(0.2)\n",
        "\n",
        "max_q1_1 = dropout_layer(max_q1_1)\n",
        "max_q2_1 = dropout_layer(max_q2_1)\n",
        "\n",
        "flat = Flatten()\n",
        "max_q1_1=flat(max_q1_1)\n",
        "max_q2_1=flat(max_q2_1)\n",
        "\n",
        "conv_second = Conv1D(filters=64,kernel_size=2,activation='relu')\n",
        "\n",
        "conv_q1_2 = conv_second(embedded_q1)\n",
        "conv_q2_2 = conv_second(embedded_q2)\n",
        "\n",
        "max_pool_second=MaxPooling1D(pool_size=2)\n",
        "\n",
        "max_q1_2=max_pool_second(conv_q1_2)\n",
        "max_q2_2=max_pool_second(conv_q2_2)\n",
        "\n",
        "dropout_layer = Dropout(0.2)\n",
        "\n",
        "max_q1_2 = dropout_layer(max_q1_2)\n",
        "max_q2_2 = dropout_layer(max_q2_2)\n",
        "\n",
        "\n",
        "flat = Flatten()\n",
        "max_q1_2=flat(max_q1_2)\n",
        "max_q2_2=flat(max_q2_2)\n",
        "\n",
        "\n",
        "conv_out_1=add([max_q1_1,max_q1_2])\n",
        "conv_out_2=add([max_q2_1,max_q2_2])\n",
        "\n",
        "bn_one = BatchNormalization()\n",
        "\n",
        "bn_q1 = bn_one(conv_out_1)\n",
        "bn_q2 = bn_one(conv_out_2)\n",
        "\n",
        "concat_input = concatenate([bn_q1,bn_q2])\n",
        "check_duplicate = Dense(1, activation='sigmoid')(concat_input)\n",
        "\n",
        "model = Model(inputs=[input_q1,input_q2], outputs=check_duplicate)\n",
        "model.summary()\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam',\\\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "callbacks = [ModelCheckpoint('question_pairs_weights_type2.h5',\\\n",
        "                             monitor='val_acc', save_best_only=True)]\n",
        "\n",
        "\n",
        "steps=len(train_q1)//batch_size\n",
        "history = model.fit([train_q1,train_q2],\n",
        "                    np.expand_dims(y_train,axis=-1),\n",
        "                    epochs=5,\n",
        "                    batch_size=10,\n",
        "                    callbacks=callbacks)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_9\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_19 (InputLayer)           [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_20 (InputLayer)           [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_9 (Embedding)         (None, 50, 300)      13730400    input_19[0][0]                   \n",
            "                                                                 input_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_6 (Conv1D)               (None, 48, 64)       57664       embedding_9[0][0]                \n",
            "                                                                 embedding_9[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_7 (Conv1D)               (None, 49, 64)       38464       embedding_9[0][0]                \n",
            "                                                                 embedding_9[1][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_6 (MaxPooling1D)  (None, 24, 64)       0           conv1d_6[0][0]                   \n",
            "                                                                 conv1d_6[1][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_7 (MaxPooling1D)  (None, 24, 64)       0           conv1d_7[0][0]                   \n",
            "                                                                 conv1d_7[1][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 24, 64)       0           max_pooling1d_6[0][0]            \n",
            "                                                                 max_pooling1d_6[1][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_19 (Dropout)            (None, 24, 64)       0           max_pooling1d_7[0][0]            \n",
            "                                                                 max_pooling1d_7[1][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_6 (Flatten)             (None, 1536)         0           dropout_18[0][0]                 \n",
            "                                                                 dropout_18[1][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten_7 (Flatten)             (None, 1536)         0           dropout_19[0][0]                 \n",
            "                                                                 dropout_19[1][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 1536)         0           flatten_6[0][0]                  \n",
            "                                                                 flatten_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 1536)         0           flatten_6[1][0]                  \n",
            "                                                                 flatten_7[1][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 1536)         6144        add_18[0][0]                     \n",
            "                                                                 add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 3072)         0           batch_normalization_9[0][0]      \n",
            "                                                                 batch_normalization_9[1][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1)            3073        concatenate_3[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 13,835,745\n",
            "Trainable params: 102,273\n",
            "Non-trainable params: 13,733,472\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5\n",
            "9997/9999 [============================>.] - ETA: 0s - loss: 0.6273 - accuracy: 0.6609WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "9999/9999 [==============================] - 148s 15ms/step - loss: 0.6273 - accuracy: 0.6609\n",
            "Epoch 2/5\n",
            "9998/9999 [============================>.] - ETA: 0s - loss: 0.5933 - accuracy: 0.6866WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "9999/9999 [==============================] - 149s 15ms/step - loss: 0.5933 - accuracy: 0.6866\n",
            "Epoch 3/5\n",
            "9999/9999 [==============================] - ETA: 0s - loss: 0.5738 - accuracy: 0.6995WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r9999/9999 [==============================] - 146s 15ms/step - loss: 0.5738 - accuracy: 0.6995\n",
            "Epoch 4/5\n",
            "9998/9999 [============================>.] - ETA: 0s - loss: 0.5621 - accuracy: 0.7107WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r9999/9999 [==============================] - 147s 15ms/step - loss: 0.5621 - accuracy: 0.7107\n",
            "Epoch 5/5\n",
            "9998/9999 [============================>.] - ETA: 0s - loss: 0.5499 - accuracy: 0.7188WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r9999/9999 [==============================] - 147s 15ms/step - loss: 0.5499 - accuracy: 0.7188\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
